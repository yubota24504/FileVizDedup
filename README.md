# FileVizDedup - ローカルLLM制御を学ぶための重複ファイル可視化・説明ツール

## 1. プロジェクト概要

FileVizDedupは、ローカル環境で動作する重複ファイル検出・可視化ツールです。単に重複ファイルを見つけるだけでなく、ローカルLLM（Ollama）と連携し、「なぜそれが重複と判断されたのか」を自然言語で説明させる機能を特徴としています。

このプロジェクトの主な目的は、クラウドAIに頼らず、手元の環境でLLMを動かし、その挙動をプロンプトエンジニアリングによって精密に制御する技術を学ぶことにあります。AIは判断を行わず、ルールベースの判定結果を人間に分かりやすく「説明する」役割に徹します。

---

## 2. 学習目的・コンセプト

本プロジェクトは、「LLMをブラックボックスとして使わない」という思想に基づいています。

- **AIに「判断」させるのではなく、「説明」させる**
  重複ファイルの判定は、hash値やファイルサイズに基づく明確なルール（ルールベース）で行います。LLMは、その判定結果の根拠をユーザーに分かりやすく解説するためにのみ使用されます。これにより、システムのコアロジックを人間が完全に制御下に置くことができます。

- **プロンプトによるLLMの出力制御を学ぶ**
  LLMの出力を安定させるため、「日本語での回答」や「根拠のない推測の禁止」などをプロンプトで厳密に制約します。LLMの自由な発想を活かすのではなく、意図した通りの出力を得ることが目的です。

- **ローカルLLMの仕組みを理解する**
  Ollamaが提供するHTTP APIを直接叩き、モデルの指定や言語の制御を体験することで、ローカルLLMがどのように動作するかの基礎を学びます。

このツールは、AI開発の初心者〜中級者が、LLMをより深く理解し、その応用の一歩を踏み出すための練習用プロジェクトとして設計されています。

---

## 3. 主な機能

- **ディレクトリスキャン**: 指定したフォルダ内のファイル構造を解析します。
- **ファイルサイズ可視化**: どのフォルダやファイルがディスク容量を占有しているかをグラフで表示します。
- **hashによる重複検出**: ファイルのハッシュ値（SHA256）を比較し、内容が完全に同一のファイルを検出します。
- **重複による無駄容量の算出**: 重複ファイルによってどれだけのディスク容量が無駄になっているかを計算します。
- **AI（Ollama）による重複理由の説明**: なぜファイルが重複しているのか、その技術的根拠を自然言語で説明します。
  - **日本語対応**: AIによる説明は日本語で生成されます。
  - **推測禁止**: 説明は入力された`hash`, `size`, `path`の情報のみを根拠とし、ファイル内容に関する推測（例：「同じ音楽ファイル」）を行いません。

---

## 4. AIモードの設計思想

本ツールは「最初からAIモードで動作する」ことを前提としており、LLMの挙動を以下の通り厳格に制限しています。これは、LLMの持つ「それらしさ」や「幻覚（ハルシネーション）」を排除し、事実に基づいた説明のみを生成させるための意図的な設計です。

- **日本語出力の強制**: プロンプトで日本語以外の出力を禁止しています。
- **推測の禁止**: ファイルの中身（音楽、動画、メタデータ等）をAIは確認できません。そのため、提供された技術的根拠から判断できない事柄への言及を固く禁じています。
- **技術的根拠に基づく説明**: 説明は必ず`hash`, `size`, `path`の情報を元に行われます。

---

## 5. AIによる説明機能の仕様（件数制限について）

「AIによる重複理由の説明」機能は、意図的に一度に処理できる件数に制限を設けています。

重複ファイルグループが多数見つかった場合、デフォルトでは**先頭の一部のグループに対してのみ**AIによる説明が生成されます。すべての重複グループを一度に説明する設計とはなっておらず、途中から説明が表示されないのは**バグではなく仕様**です。

### 設計上の理由

この制限は、ローカル環境でLLMを安全かつ現実的なパフォーマンスで利用するために導入されています。

- **ローカルLLMへの過剰リクエスト防止**: すべての重複グループに対して説明を生成すると、お使いのPC上で動作するOllamaに大量のリクエストが送られ、システムのパフォーマンスが大幅に低下する可能性があります。
- **応答性の維持**: 一括処理によるタイムアウトや、UIの応答遅延を回避します。

### AIの役割について

繰り返しになりますが、本ツールにおいて重複判定そのものは`hash`値や`size`に基づくルールベースで行われており、AIは一切関与していません。AIの役割は、あくまでその判定結果を人間が理解しやすいように「翻訳」する補助的なものです。

この件数制限は、「AIに何でも自動でやらせる」のではなく、「人間が主体となり、AIを補助として適切に使う」という本学習プロジェクトの思想を反映したものです。

---

## 6. 使用技術

- **バックエンド**: Python, FastAPI
- **フロントエンド**: Vanilla JavaScript, HTML, CSS
- **ローカルLLM**: Ollama
- **重複検出ロジック**: ファイルサイズおよびSHA256ハッシュ値に基づく比較

---

## 7. 実行方法（Windowsローカル環境）

本ツールは、いくつかのコンポーネントを連携させて動作させます。

1.  **Ollamaの起動とモデルの準備**
    - [Ollama公式サイト](https://ollama.com/)からアプリケーションをインストールし、起動します。
    - コマンドプロンプトで以下のコマンドを実行し、AIモデルをダウンロードします。
      ```bash
      ollama pull llama3
      ```

2.  **依存ライブラリのインストール**
    - このリポジトリにある `install_requirements.bat` をダブルクリックして実行します。
    - FastAPIなどのPythonライブラリがインストールされます。（初回のみ）

3.  **FastAPIサーバーの起動**
    - `run_app.bat` をダブルクリックして実行します。
    - 黒いコマンドプロンプト画面が起動し、サーバーが待機状態になります。

4.  **ブラウザでアクセス**
    - Webブラウザで `http://127.0.0.1:8000` を開きます。
    - FileVizDedupの画面が表示されれば成功です。

---

## 8. 注意事項・免責

- 本プロジェクトは、ローカルLLMの制御方法を学ぶことを主目的とした**実験・学習用途のツール**です。
- 大容量のディレクトリや数百万のファイルが含まれるディレクトリをスキャンすると、PCの動作が非常に遅くなる可能性があります。最初は小規模なフォルダでお試しください。
- ファイルの削除機能は強力です。削除するファイルは、必ずご自身の責任で確認してください。本ツールの使用によって生じたいかなる損害についても、開発者は責任を負いません。